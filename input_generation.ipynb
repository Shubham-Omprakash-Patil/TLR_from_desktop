{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import _init_paths\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.image import flip, color_aug\n",
    "from lib.image import get_affine_transform, affine_transform\n",
    "from lib.image import gaussian_radius, draw_umich_gaussian, draw_msra_gaussian\n",
    "from lib.image import draw_dense_reg, draw_dense_reg_cls_nb\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/home/chulhoon/Desktop/ad-db/samples_tl_train.txt'\n",
    "anno_path = '/home/chulhoon/Desktop/ad-db/box_2d_annotations'\n",
    "\n",
    "ia.seed(2)\n",
    "\n",
    "class MagnaAdTlDataset(Dataset):\n",
    "    def __init__(self, image_path, anno_path, aug=True, debug=False):\n",
    "        self.image_path = image_path\n",
    "        self.anno_path = anno_path        \n",
    "\n",
    "        self.images = {}\n",
    "        idx = 0\n",
    "        if self.image_path.endswith('.txt'):\n",
    "            with open(self.image_path, 'r') as f:\n",
    "                for l in f:\n",
    "                    self.images[idx] = l.split('\\n')[0]\n",
    "                    idx += 1\n",
    "            self.image_path = self.image_path.split('samples')[0] + 'rgb_images'\n",
    "        else:\n",
    "            for l in os.listdir(image_path):\n",
    "                self.images[idx] = l \n",
    "                idx += 1\n",
    "\n",
    "        self.total_num_images = idx\n",
    "\n",
    "        self.rois = []\n",
    "        self.rois.append(np.array([0,    0,     1000,    500]))\n",
    "        self.rois.append(np.array([920,  0,     1000,    500]))\n",
    "        self.rois.append(np.array([30,   320,    480,    240]))\n",
    "        self.rois.append(np.array([490,  320,    480,    240]))\n",
    "        self.rois.append(np.array([950,  320,    480,    240]))\n",
    "        self.rois.append(np.array([1410, 320,    480,    240]))\n",
    "        self.rois.append(np.array([55,   515,    210,    105]))\n",
    "        self.rois.append(np.array([255,  515,    210,    105]))\n",
    "        self.rois.append(np.array([455,  515,    210,    105]))\n",
    "        self.rois.append(np.array([655,  515,    210,    105]))\n",
    "        self.rois.append(np.array([855,  515,    210,    105]))\n",
    "        self.rois.append(np.array([1055,  515,    210,    105]))\n",
    "        self.rois.append(np.array([1255,  515,    210,    105]))\n",
    "        self.rois.append(np.array([1455,  515,    210,    105]))\n",
    "        self.rois.append(np.array([1655,  515,    210,    105]))\n",
    "        self.rois = np.array(self.rois)\n",
    "        self.rois[:,2] = self.rois[:,0] + self.rois[:,2]\n",
    "        self.rois[:,3] = self.rois[:,1] + self.rois[:,3]\n",
    "\n",
    "        self.seq = iaa.Sequential([\n",
    "                                    #\n",
    "                                    iaa.MultiplySaturation((0.2, 1.0), from_colorspace=iaa.CSPACE_BGR),\n",
    "                                    # apply the following augmenters to most images\n",
    "                                    # iaa.Fliplr(0.5),  # horizontally flip 50% of all images                                    \n",
    "                                    # # crop images by -5% to 10% of their height/width\n",
    "                                    # iaa.Sometimes(0.5, iaa.CropAndPad(\n",
    "                                    #     percent=(-0.1, 0.1),\n",
    "                                    #     pad_mode='constant',\n",
    "                                    #     pad_cval=(0)\n",
    "                                    # )),                                    \n",
    "                                    # iaa.Sometimes(0.5, iaa.Affine(\n",
    "                                    #     # scale images to 80-120% of their size, individually per axis\n",
    "                                    #     scale={\"x\": (1.0, 1.4), \"y\": (1.0, 1.4)},        \n",
    "                                    #     translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},        \n",
    "                                    #     #rotate=(-45, 45),  # rotate by -15 to +15 degrees\n",
    "                                    #     # use nearest neighbour or bilinear interpolation (fast)\n",
    "                                    #     order=[0, 1],\n",
    "                                    #     # if mode is constant, use a cval between 0 and 255\n",
    "                                    #     cval=(0),\n",
    "                                    #     # # use any of scikit-image's warping modes\n",
    "                                    #     # # (see 2nd image from the top for examples)\n",
    "                                    #     mode='constant'\n",
    "                                    # )),            \n",
    "                                    # # execute 0 to 5 of the following (less important) augmenters per\n",
    "                                    # # image don't execute all of them, as that would often be way too\n",
    "                                    # # strong\n",
    "                                    # iaa.SomeOf((0, 5),\n",
    "                                    #         [\n",
    "                                    #         iaa.OneOf([\n",
    "                                    #         # blur images with a sigma between 0 and 3.0\n",
    "                                    #         iaa.GaussianBlur((0, 1.5)),\n",
    "                                    #         # blur image using local means with kernel sizes\n",
    "                                    #         # between 2 and 7\n",
    "                                    #         iaa.AverageBlur(k=(3, 5)),\n",
    "                                    #         # blur image using local medians with kernel sizes\n",
    "                                    #         # between 2 and 7\n",
    "                                    #         iaa.MedianBlur(k=(3, 5)),\n",
    "                                    #     ]),\n",
    "                                    #     iaa.Sharpen(alpha=(0, 1.0), lightness=(\n",
    "                                    #                 0.75, 1.5)),  # sharpen images                \n",
    "                                    #     # search either for all edges or for directed edges,\n",
    "                                    #     # blend the result with the original image using a blobby mask\n",
    "                                        \n",
    "                                    #     # # add gaussian noise to images\n",
    "                                    #     iaa.AdditiveGaussianNoise(loc=0, scale=(\n",
    "                                    #         0.0, 0.05*255), per_channel=0.5),                                        \n",
    "                                    #     # # change brightness of images (by -10 to 10 of original value)\n",
    "                                    #     iaa.Add((-10, 10), per_channel=0.5),\n",
    "                                    #     # # change hue and saturation\n",
    "                                    #     #iaa.AddToHueAndSaturation((-2, 2)),\n",
    "                                    #     # # either change the brightness of the whole image (sometimes\n",
    "                                    #     # # per channel) or change the brightness of subareas\n",
    "                                    #     # iaa.OneOf([\n",
    "                                    #     #     iaa.Multiply(\n",
    "                                    #     #                 (0.5, 1.5), per_channel=0.5),\n",
    "                                    #     #     iaa.BlendAlphaFrequencyNoise(\n",
    "                                    #     #         exponent=(-4, 0),\n",
    "                                    #     #         foreground=iaa.Multiply(\n",
    "                                    #     #             (0.5, 1.5), per_channel=True),\n",
    "                                    #     #         background=iaa.contrast.LinearContrast(\n",
    "                                    #     #             (0.5, 2.0))\n",
    "                                    #     #     )\n",
    "                                    #     #]),                                                 \n",
    "                                    ],\n",
    "                                        random_order=True\n",
    "                                    )            \n",
    "                                ],\n",
    "                                random_order=True)        \n",
    "\n",
    "        # options\n",
    "        self.pad = 31        \n",
    "        self.scale = 0.4        \n",
    "        self.down_ratio = 4\n",
    "        self.num_classes = 2        \n",
    "        self.max_objs = 20\n",
    "        self.dense_wh = True\n",
    "        self.reg_offset = True  \n",
    "        self.radius_scale = 3.0      \n",
    "\n",
    "        # debug\n",
    "        self.aug = aug\n",
    "        self.debug = debug\n",
    "\n",
    "    def create_new_bbox(self, img, roi, tl_box, resize_size, min_width=6):\n",
    "        img_roi = np.copy(img[roi[1]:roi[3],roi[0]:roi[2],:])        \n",
    "        roi_h, roi_w, _ = img_roi.shape\n",
    "\n",
    "        if len(tl_box) != 0:\n",
    "            new_tl_box = np.copy(tl_box).astype(np.float)            \n",
    "            new_tl_box[:,[3,5]] = tl_box[:,[3,5]] - roi[0]\n",
    "            new_tl_box[:,[4,6]] = tl_box[:,[4,6]] - roi[1]\n",
    "\n",
    "            new_tl_box = new_tl_box[new_tl_box[:,3] >= 0   , :]\n",
    "            new_tl_box = new_tl_box[new_tl_box[:,4] >= 0   , :]\n",
    "            new_tl_box = new_tl_box[new_tl_box[:,5] < roi_w, :]\n",
    "            new_tl_box = new_tl_box[new_tl_box[:,6] < roi_h, :]\n",
    "            \n",
    "            resize_ratio = resize_size[0]/float(roi_w)\n",
    "            new_bbox = new_tl_box[:,3:].astype(np.float) * resize_ratio            \n",
    "            new_bbox_w = new_bbox[:,2]-new_bbox[:,0]\n",
    "            new_bbox = new_bbox[new_bbox_w>=min_width]\n",
    "            new_tl_box = new_tl_box[new_bbox_w>=min_width]\n",
    "            new_tl_box[:,3:] = new_bbox            \n",
    "        else:\n",
    "            new_tl_box = []\n",
    "\n",
    "        new_img = cv2.resize(img_roi, resize_size)\n",
    "\n",
    "        return new_img, new_tl_box\n",
    "\n",
    "    def get_item_single(self, idx):        \n",
    "        img = cv2.imread(os.path.join(self.image_path, self.images[idx]))\n",
    "        anno = self.get_annotations(self.images[idx])\n",
    "\n",
    "        return img, anno\n",
    "\n",
    "    def get_item(self, idx):        \n",
    "        img = cv2.imread(os.path.join(self.image_path, self.images[idx]))\n",
    "        anno = self.get_annotations(self.images[idx])\n",
    "\n",
    "        imgs = []\n",
    "        annos = []        \n",
    "        none_imgs = []\n",
    "        none_annos = []\n",
    "\n",
    "        for roi in self.rois:\n",
    "            new_img, new_anno = self.create_new_bbox(img, roi, anno, (320, 160), 4)     \n",
    "\n",
    "            if len(new_anno) != 0:\n",
    "                imgs.append(new_img)\n",
    "                annos.append(new_anno)                \n",
    "            else:\n",
    "                none_imgs.append(new_img)\n",
    "                none_annos.append(new_anno)\n",
    "\n",
    "        if len(annos) != 0:            \n",
    "            return imgs, annos\n",
    "        else:\n",
    "            return [none_imgs[-1]], [none_annos[-1]]\n",
    "\n",
    "    def get_annotations(self, image_name):\n",
    "        file_name = image_name.split('.')[0] + '.txt'\n",
    "        anno_file = open(os.path.join(self.anno_path, file_name), 'r')\n",
    "        \n",
    "        bbs = []\n",
    "        for l in anno_file.readlines():\n",
    "            if 'light' in l:\n",
    "                items = l.split(',')\n",
    "                \n",
    "                cls = int(items[4])\n",
    "                nb = int(items[5])\n",
    "                x1 = int(items[6])\n",
    "                y1 = int(items[7])\n",
    "                x2 = int(items[8])\n",
    "                y2 = int(items[9])\n",
    "                bbs.append(np.array([1, cls, nb, x1, y1, x2, y2]))            \n",
    "        \n",
    "        return np.array(bbs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def encode(self, img, anno):\n",
    "        # convert numpy to BoundingBox for data augmentation        \n",
    "        ann_bbs = []\n",
    "        for ann in anno:\n",
    "            label = '{}_{}_{}'.format(int(ann[0]),int(ann[1]),int(ann[2]))\n",
    "            ann_bbs.append(BoundingBox(x1=ann[3], y1=ann[4], x2=ann[5], y2=ann[6], label=label))\n",
    "        \n",
    "        ann_bbs_oi = BoundingBoxesOnImage(ann_bbs, shape=img.shape)\n",
    "        if self.aug:\n",
    "            img_aug, ann_bbs_oi_aug = self.seq(image=img, bounding_boxes=ann_bbs_oi)\n",
    "        else:\n",
    "            img_aug = img\n",
    "            ann_bbs_oi_aug = ann_bbs_oi\n",
    "\n",
    "        # remove samples outside image\n",
    "        ann_bbs_oi_aug = ann_bbs_oi_aug.remove_out_of_image(partly=True)\n",
    "\n",
    "        num_objs = min(len(ann_bbs_oi_aug), self.max_objs)\n",
    "\n",
    "        # center \n",
    "        height, width = img_aug.shape[0], img_aug.shape[1]        \n",
    "        c = np.array([width / 2, height / 2], dtype=np.float32)\n",
    "\n",
    "        # input size\n",
    "        input_h = (height | self.pad) + 1\n",
    "        input_w = (width | self.pad) + 1\n",
    "        s = np.array([input_w, input_h], dtype=np.float32)               \n",
    "\n",
    "        trans_input = get_affine_transform(c, s, 0, [input_w, input_h])        \n",
    "        inp = cv2.warpAffine(img_aug, trans_input, (input_w, input_h),flags=cv2.INTER_LINEAR)\n",
    "\n",
    "        if self.debug: \n",
    "            inp_debug = inp.copy()\n",
    "\n",
    "        inp = (inp.astype(np.float32) / 255.)\n",
    "        inp = inp.transpose(2, 0, 1) # channel, height, width\n",
    "\n",
    "        # output size\n",
    "        output_h = input_h // self.down_ratio\n",
    "        output_w = input_w // self.down_ratio\n",
    "        trans_output = get_affine_transform(c, s, 0, [output_w, output_h])        \n",
    "\n",
    "        num_classes = self.num_classes\n",
    "        \n",
    "        # initalize outputs\n",
    "        hm = np.zeros((num_classes, output_h, output_w), dtype=np.float32)\n",
    "        wh = np.zeros((self.max_objs, 2), dtype=np.float32)\n",
    "        dense_wh = np.zeros((2, output_h, output_w), dtype=np.float32)\n",
    "        reg = np.zeros((self.max_objs, 2), dtype=np.float32)\n",
    "        ind = np.zeros((self.max_objs), dtype=np.int64)\n",
    "        reg_mask = np.zeros((self.max_objs), dtype=np.uint8)\n",
    "        cat_spec_wh = np.zeros((self.max_objs, num_classes * 2), dtype=np.float32)\n",
    "        cat_spec_mask = np.zeros((self.max_objs, num_classes * 2), dtype=np.uint8)\n",
    "\n",
    "        output_tl_cls = np.zeros((output_h, output_w), dtype=np.uint8)\n",
    "        output_tl_nb = np.zeros((output_h, output_w), dtype=np.uint8)\n",
    "        \n",
    "        draw_gaussian = draw_umich_gaussian\n",
    "\n",
    "        gt_det = []\n",
    "\n",
    "        if self.debug:\n",
    "            output_debug = cv2.warpAffine(img_aug, trans_output, (output_w, output_h), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "        for k in range(num_objs):\n",
    "            ann = ann_bbs_oi_aug[k]\n",
    "            bbox = np.array([ann.x1, ann.y1, ann.x2, ann.y2])            \n",
    "            cls_id = int(ann.label.split('_')[0]) # object: 0 - no object 1 - tl \n",
    "            tl_cls = int(ann.label.split('_')[1]) # traffic light status: green, red, yellow, ...\n",
    "            tl_nb = int(ann.label.split('_')[2]) # number of bulbs: three, four, and five\n",
    "                    \n",
    "            if self.debug: \n",
    "                img_aug = img_aug.copy()\n",
    "                bbox_int = bbox.astype(np.int)\n",
    "                cv2.rectangle(img_aug, (bbox_int[0],bbox_int[1]), (bbox_int[2],bbox_int[3]), (0,255,0), 1)\n",
    "\n",
    "            bbox[:2] = affine_transform(bbox[:2], trans_output)\n",
    "            bbox[2:] = affine_transform(bbox[2:], trans_output)\n",
    "            bbox[[0, 2]] = np.clip(bbox[[0, 2]], 0, output_w - 1)\n",
    "            bbox[[1, 3]] = np.clip(bbox[[1, 3]], 0, output_h - 1)            \n",
    "\n",
    "            if self.debug: \n",
    "                bbox_int = bbox.astype(np.int)\n",
    "                cv2.rectangle(output_debug, (bbox_int[0],bbox_int[1]), (bbox_int[2],bbox_int[3]), (0,255,0), 1)\n",
    "\n",
    "            h, w = bbox[3] - bbox[1], bbox[2] - bbox[0]\n",
    "            if h > 0 and w > 0:\n",
    "                radius = gaussian_radius((math.ceil(h)*self.radius_scale, math.ceil(w)*self.radius_scale))\n",
    "                radius = max(0, int(radius))\n",
    "                radius = radius\n",
    "                ct = np.array([(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2], dtype=np.float32)\n",
    "                ct_int = ct.astype(np.int32)                \n",
    "                draw_gaussian(hm[cls_id], ct_int, radius)\n",
    "                wh[k] = 1. * w, 1. * h\n",
    "                ind[k] = ct_int[1] * output_w + ct_int[0]\n",
    "                reg[k] = ct - ct_int\n",
    "                reg_mask[k] = 1\n",
    "                cat_spec_wh[k, cls_id * 2: cls_id * 2 + 2] = wh[k]\n",
    "                cat_spec_mask[k, cls_id * 2: cls_id * 2 + 2] = 1\n",
    "                if self.dense_wh:\n",
    "                    #draw_dense_reg(dense_wh, hm.max(axis=0), ct_int, wh[k], radius)\n",
    "                    dense_wh, output_tl_cls, output_tl_nb = draw_dense_reg_cls_nb(dense_wh, output_tl_cls, output_tl_nb, hm.max(axis=0), ct_int, wh[k], tl_cls, tl_nb, radius)                    \n",
    "                    \n",
    "                gt_det.append([ct[0] - w / 2, ct[1] - h / 2, \n",
    "                            ct[0] + w / 2, ct[1] + h / 2, 1, cls_id])       \n",
    "        if self.debug:         \n",
    "            cv2.namedWindow('original image',0)\n",
    "            cv2.imshow('original image', img_aug)\n",
    "            cv2.namedWindow('input_debug',0)\n",
    "            cv2.imshow('input_debug', inp_debug)\n",
    "            cv2.namedWindow('output_debug',0)            \n",
    "            cv2.imshow('output_debug', output_debug)\n",
    "            \n",
    "            cv2.namedWindow('hm', 0)\n",
    "            cv2.imshow('hm', hm.transpose((1,2,0))[:,:,1])\n",
    "            print('hm')\n",
    "            print(np.unique(hm))\n",
    "                        \n",
    "            cv2.namedWindow('wh', 0)\n",
    "            cv2.imshow('wh', dense_wh.transpose((1,2,0))[:,:,1])\n",
    "            print('wh')\n",
    "            print(np.unique(wh))\n",
    "\n",
    "            cv2.namedWindow('cls', 0)\n",
    "            cv2.imshow('cls', output_tl_cls)\n",
    "            print('cls')\n",
    "            print(np.unique(output_tl_cls))\n",
    "\n",
    "            cv2.namedWindow('nb', 0)\n",
    "            cv2.imshow('nb', output_tl_nb)\n",
    "            print('nb')\n",
    "            print(np.unique(output_tl_nb))\n",
    "\n",
    "            cv2.waitKey()            \n",
    "\n",
    "        ret = {'input': inp, 'hm': hm, 'reg_mask': reg_mask, 'ind': ind, 'wh': wh, 'cls': output_tl_cls, 'nb': output_tl_nb}\n",
    "        \n",
    "        if self.dense_wh:\n",
    "            hm_a = hm.max(axis=0, keepdims=True)\n",
    "            dense_wh_mask = np.concatenate([hm_a, hm_a], axis=0)\n",
    "            ret.update({'dense_wh': dense_wh, 'dense_wh_mask': dense_wh_mask})\n",
    "            del ret['wh']\n",
    "\n",
    "        if self.reg_offset:\n",
    "            ret.update({'reg': reg})\n",
    "            \n",
    "        return ret\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        imgs, annos = self.get_item(idx)\n",
    "        \n",
    "        rets = []\n",
    "        for img, anno in zip(imgs, annos):\n",
    "            ret = self.encode(img, anno)\n",
    "            rets.append(ret)\n",
    "\n",
    "        return rets  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MagnaAdTlDataset(image_path, anno_path, aug=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hm\n[0.         0.00315111 0.02732372 0.05613476 0.23692776 0.48675224\n 1.        ]\nwh\n[0.        1.60392   1.804409  1.8044128 4.4467335 4.640068  4.64007  ]\ncls\n[0 1 2]\nnb\n[0 1]\nhm\n[0.         0.00315111 0.01831564 0.02732372 0.05613476 0.13533528\n 0.23692776 0.48675224 1.        ]\nwh\n[0.        1.5238094 2.666668  3.0476189]\ncls\n[0 1]\nnb\n[0 1]\n"
    }
   ],
   "source": [
    "rets = dataset.__getitem__(4000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ret in rets:\n",
    "    cv2.namedWindow('hm', 0)\n",
    "    cv2.imshow('hm', ret['hm'].transpose((1,2,0))[:,:,1])\n",
    "    if 27 == cv2.waitKey():\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hm\n[0.         0.00315111 0.02732372 0.05613476 0.23692776 0.48675224\n 1.        ]\nwh\n[0.        1.3544922 1.3544998 3.314499  3.615818 ]\ncls\n[0 1 2]\nnb\n[0 1]\nhm\n[0.]\nwh\n[0.]\ncls\n[0]\nnb\n[0]\nhm\n[0.         0.00134381 0.00315111 0.00843378 0.02538824 0.02732372\n 0.03665804 0.0529305  0.05613476 0.15933686 0.2300663  0.23692776\n 0.47965226 0.48675224 0.6925693  1.        ]\nwh\n[0.        1.8349495 2.0184517 4.722439  4.8052826]\ncls\n[0 2]\nnb\n[0 1]\nhm\n[0.]\nwh\n[0.]\ncls\n[0]\nnb\n[0]\nhm\n[0.00000000e+00 8.15987820e-04 3.86592024e-03 1.17436284e-02\n 1.83156393e-02 2.28734650e-02 2.85654999e-02 5.56379966e-02\n 1.08368024e-01 1.35335281e-01 1.69013321e-01 3.29192996e-01\n 4.11112279e-01 6.41180396e-01 8.00737381e-01 1.00000000e+00]\nwh\n[0.       3.333334 8.833333]\ncls\n[0 2]\nnb\n[0 1]\nhm\n[0.]\nwh\n[0.]\ncls\n[0]\nnb\n[0]\nhm\n[0.         0.00315111 0.02732372 0.05613476 0.23692776 0.48675224\n 1.        ]\nwh\n[0.        1.6666641 4.333334 ]\ncls\n[0 1]\nnb\n[0 1]\nhm\n[0.         0.00315111 0.02732372 0.05613476 0.23692776 0.48675224\n 1.        ]\nwh\n[0.        1.6894875 1.6894913 3.3273487 3.7432709]\ncls\n[0 2]\nnb\n[0 1]\nhm\n[0.]\nwh\n[0.]\ncls\n[0]\nnb\n[0]\nhm\n[0.         0.00315111 0.02732372 0.05613476 0.23692776 0.48675224\n 1.        ]\nwh\n[0.        1.3600006 3.6800003]\ncls\n[0 1]\nnb\n[0 1]\nhm\n[0.]\nwh\n[0.]\ncls\n[0]\nnb\n[0]\nhm\n[0.         0.00315111 0.02732372 0.05613476 0.23692776 0.48675224\n 1.        ]\nwh\n[0.        1.7236328 4.713644 ]\ncls\n[0 1]\nnb\n[0 1]\nhm\n[0.         0.00134381 0.00843378 0.02538824 0.03665804 0.0529305\n 0.15933686 0.2300663  0.47965226 0.6925693  1.        ]\nwh\n[0.        2.4404907 6.284094 ]\ncls\n[0 1]\nnb\n[0 1]\nhm\n[0.         0.00315111 0.02732372 0.05613476 0.23692776 0.48675224\n 1.        ]\nwh\n[0.        1.3714294 3.5443058]\ncls\n[0 2]\nnb\n[0 1]\nhm\n[0.         0.00315111 0.02732372 0.05613476 0.23692776 0.48675224\n 1.        ]\nwh\n[0.        1.1666718 3.166666 ]\ncls\n[0 2]\nnb\n[0 1]\nhm\n[0.         0.00134381 0.00843378 0.02538824 0.03665804 0.0529305\n 0.15933686 0.2300663  0.47965226 0.6925693  1.        ]\nwh\n[0.        2.4309692 5.8236103]\ncls\n[0 2]\nnb\n[0 1]\nhm\n[0.]\nwh\n[0.]\ncls\n[0]\nnb\n[0]\nhm\n[0.         0.00315111 0.02732372 0.05613476 0.23692776 0.48675224\n 1.        ]\nwh\n[0.        1.5987549 1.9984398 3.4940853 3.8823166]\ncls\n[0 2]\nnb\n[0 1]\nhm\n[0.         0.00315111 0.02732372 0.05613476 0.23692776 0.48675224\n 1.        ]\nwh\n[0.       1.666666 4.      ]\ncls\n[0 1]\nnb\n[0 1]\nhm\n[0.]\nwh\n[0.]\ncls\n[0]\nnb\n[0]\n0\ntorch.Size([8, 3, 192, 352])\ntorch.Size([8, 2, 48, 88])\ntorch.Size([8, 20, 2])\ntorch.Size([8, 20])\ntorch.Size([8, 20])\ntorch.Size([8, 2, 48, 88])\ntorch.Size([8, 2, 48, 88])\ntorch.Size([8, 48, 88])\ntorch.Size([8, 48, 88])\n"
    }
   ],
   "source": [
    "for iter_id, rets in enumerate(train_dataloader):\n",
    "    print(iter_id)\n",
    "    batch_input = []\n",
    "    batch_hm = []\n",
    "    batch_reg = []\n",
    "    batch_reg_mask = []\n",
    "    batch_ind = []\n",
    "    batch_dense_wh = []\n",
    "    batch_densw_wh_mask = []\n",
    "    batch_cls = []\n",
    "    batch_nb = []\n",
    "\n",
    "    for ret in rets:\n",
    "        batch_input.append(ret['input'])\n",
    "        batch_hm.append(ret['hm'])\n",
    "        batch_reg.append(ret['reg'])\n",
    "        batch_reg_mask.append(ret['reg_mask'])\n",
    "        batch_ind.append(ret['ind'])\n",
    "        batch_dense_wh.append(ret['dense_wh'])\n",
    "        batch_densw_wh_mask.append(ret['dense_wh_mask'])\n",
    "        batch_cls.append(ret['cls'])\n",
    "        batch_nb.append(ret['nb'])\n",
    "\n",
    "    batch_input = torch.cat(batch_input, dim=0)\n",
    "    batch_hm = torch.cat(batch_hm, dim=0)\n",
    "    batch_reg = torch.cat(batch_reg, dim=0)\n",
    "    batch_reg_mask = torch.cat(batch_reg_mask, dim=0)\n",
    "    batch_ind = torch.cat(batch_ind, dim=0)\n",
    "    batch_dense_wh = torch.cat(batch_dense_wh, dim=0)\n",
    "    batch_densw_wh_mask = torch.cat(batch_densw_wh_mask, dim=0)\n",
    "    batch_cls = torch.cat(batch_cls, dim=0)\n",
    "    batch_nb = torch.cat(batch_nb, dim=0)\n",
    "\n",
    "    print(batch_input.shape)\n",
    "    print(batch_hm.shape)\n",
    "    print(batch_reg.shape)\n",
    "    print(batch_reg_mask.shape)\n",
    "    print(batch_ind.shape)\n",
    "    print(batch_dense_wh.shape)\n",
    "    print(batch_densw_wh_mask.shape)\n",
    "    print(batch_cls.shape)\n",
    "    print(batch_nb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([8, 48, 88])"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "mask = batch_densw_wh_mask[:,1,:,:]\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(94.6134)"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "batch_densw_wh_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73707810c9441992e6d760bee7847d6bab999249fc2ae3b43a9295e8a5d7ac67"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit",
   "language": "python",
   "name": "python361364bit48fbd5a6469142d583c76abc026bc711"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}